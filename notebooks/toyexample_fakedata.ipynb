{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PM4Py library available - Full process mining analysis enabled\n",
      "üìä Analysis Environment Ready\n",
      "üìã Event Log Created: 39 events across 4 cases\n",
      "üèÉ Event Types: enter_location, physical_activity, notification, self_report, exit_location\n",
      "üìç Locations: home, gym, work, park\n",
      "\n",
      "üìÑ Sample Event Log:\n",
      "case_id           timestamp             event location activity_type notification_type  stress_level\n",
      " A-Day1 2024-01-01 08:00:00    enter_location     home          None              None           NaN\n",
      " A-Day1 2024-01-01 08:30:00 physical_activity     home         light              None           NaN\n",
      " A-Day1 2024-01-01 09:00:00      notification     home          None          received           NaN\n",
      " A-Day1 2024-01-01 09:05:00       self_report     home          None              None           3.0\n",
      " A-Day1 2024-01-01 10:00:00     exit_location     home          None              None           NaN\n",
      " A-Day1 2024-01-01 10:30:00    enter_location      gym          None              None           NaN\n",
      " A-Day1 2024-01-01 11:00:00 physical_activity      gym      moderate              None           NaN\n",
      " A-Day1 2024-01-01 11:30:00 physical_activity      gym      vigorous              None           NaN\n",
      " A-Day1 2024-01-01 12:00:00      notification      gym          None          received           NaN\n",
      " A-Day1 2024-01-01 12:02:00       self_report      gym          None              None           2.0\n",
      "\n",
      "üìã Complete Event Log Structure:\n",
      "Total Events: 39\n",
      "Unique Cases: 4\n",
      "Event Types: 5\n",
      "Locations: 4\n",
      "Time Span: 2024-01-01 07:00:00 to 2024-01-02 17:00:00\n",
      "\n",
      "üìä Event Type Distribution:\n",
      "  notification: 11 (28.2%)\n",
      "  physical_activity: 8 (20.5%)\n",
      "  enter_location: 7 (17.9%)\n",
      "  exit_location: 7 (17.9%)\n",
      "  self_report: 6 (15.4%)\n",
      "\n",
      "üîÑ PM4Py Event Log Created: 4 traces\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable ProcessTree object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 151\u001b[0m\n\u001b[0;32m    148\u001b[0m dfg \u001b[38;5;241m=\u001b[39m dfg_discovery\u001b[38;5;241m.\u001b[39mapply(event_log)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# Discover process model using Inductive Miner\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m net, initial_marking, final_marking \u001b[38;5;241m=\u001b[39m inductive_miner\u001b[38;5;241m.\u001b[39mapply(event_log)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müìä Process Discovery Complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müîç Directly-Follows Graph discovered with transition frequencies\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable ProcessTree object"
     ]
    }
   ],
   "source": [
    "# Process Mining vs Other Analytical Techniques\n",
    "# Activity & Stress Monitoring Case Study\n",
    "\n",
    "\"\"\"\n",
    "This notebook demonstrates the unique advantages of process mining over traditional\n",
    "analytical techniques using a health monitoring scenario with physical activities,\n",
    "stress reporting, and location-aware behavioral patterns.\n",
    "\"\"\"\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Process mining libraries\n",
    "try:\n",
    "    import pm4py\n",
    "    from pm4py.objects.conversion.log import converter as log_converter\n",
    "    from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "    from pm4py.visualization.petri_net import visualizer as pn_visualizer\n",
    "    from pm4py.visualization.dfg import visualizer as dfg_visualizer\n",
    "    from pm4py.algo.discovery.dfg import algorithm as dfg_discovery\n",
    "    from pm4py.statistics.traces.generic.log import case_statistics\n",
    "    pm4py_available = True\n",
    "    print(\"‚úÖ PM4Py library available - Full process mining analysis enabled\")\n",
    "except ImportError:\n",
    "    pm4py_available = False\n",
    "    print(\"‚ö†Ô∏è PM4Py not available - Using alternative visualization methods\")\n",
    "\n",
    "print(\"üìä Analysis Environment Ready\")\n",
    "\n",
    "# ## 1. Create Synthetic Event Log Data\n",
    "\n",
    "# Create comprehensive event log with parallel pathways and contextual variables\n",
    "event_data = []\n",
    "\n",
    "# Helper function to add events\n",
    "def add_event(case_id, timestamp, event, location, activity_type=None, notification_type=None, stress_level=None):\n",
    "    event_data.append({\n",
    "        'case_id': case_id,\n",
    "        'timestamp': timestamp,\n",
    "        'event': event,\n",
    "        'location': location,\n",
    "        'activity_type': activity_type,\n",
    "        'notification_type': notification_type,\n",
    "        'stress_level': stress_level\n",
    "    })\n",
    "\n",
    "# User A - Day 1: Home -> Gym pattern with good compliance\n",
    "base_time = datetime(2024, 1, 1, 8, 0)\n",
    "add_event('A-Day1', base_time, 'enter_location', 'home')\n",
    "add_event('A-Day1', base_time + timedelta(minutes=30), 'physical_activity', 'home', 'light')\n",
    "add_event('A-Day1', base_time + timedelta(minutes=60), 'notification', 'home', notification_type='received')\n",
    "add_event('A-Day1', base_time + timedelta(minutes=65), 'self_report', 'home', stress_level=3)\n",
    "add_event('A-Day1', base_time + timedelta(minutes=120), 'exit_location', 'home')\n",
    "add_event('A-Day1', base_time + timedelta(minutes=150), 'enter_location', 'gym')\n",
    "add_event('A-Day1', base_time + timedelta(minutes=180), 'physical_activity', 'gym', 'moderate')\n",
    "add_event('A-Day1', base_time + timedelta(minutes=210), 'physical_activity', 'gym', 'vigorous')\n",
    "add_event('A-Day1', base_time + timedelta(minutes=240), 'notification', 'gym', notification_type='received')\n",
    "add_event('A-Day1', base_time + timedelta(minutes=242), 'self_report', 'gym', stress_level=2)\n",
    "add_event('A-Day1', base_time + timedelta(minutes=270), 'exit_location', 'gym')\n",
    "\n",
    "# User A - Day 2: Work stress pattern with missed notifications\n",
    "base_time = datetime(2024, 1, 2, 8, 0)\n",
    "add_event('A-Day2', base_time, 'enter_location', 'work')\n",
    "add_event('A-Day2', base_time + timedelta(minutes=120), 'notification', 'work', notification_type='received')\n",
    "add_event('A-Day2', base_time + timedelta(minutes=150), 'notification', 'work', notification_type='received')\n",
    "add_event('A-Day2', base_time + timedelta(minutes=180), 'self_report', 'work', stress_level=7)\n",
    "add_event('A-Day2', base_time + timedelta(minutes=360), 'physical_activity', 'work', 'light')\n",
    "add_event('A-Day2', base_time + timedelta(minutes=420), 'notification', 'work', notification_type='received')\n",
    "add_event('A-Day2', base_time + timedelta(minutes=540), 'exit_location', 'work')\n",
    "\n",
    "# User B - Day 1: Multi-location active day with parallel activities\n",
    "base_time = datetime(2024, 1, 1, 7, 0)\n",
    "add_event('B-Day1', base_time, 'enter_location', 'home')\n",
    "add_event('B-Day1', base_time + timedelta(minutes=30), 'physical_activity', 'home', 'light')\n",
    "add_event('B-Day1', base_time + timedelta(minutes=60), 'notification', 'home', notification_type='received')\n",
    "add_event('B-Day1', base_time + timedelta(minutes=60), 'self_report', 'home', stress_level=4)  # Parallel\n",
    "add_event('B-Day1', base_time + timedelta(minutes=120), 'exit_location', 'home')\n",
    "add_event('B-Day1', base_time + timedelta(minutes=150), 'enter_location', 'park')\n",
    "add_event('B-Day1', base_time + timedelta(minutes=180), 'physical_activity', 'park', 'moderate')\n",
    "add_event('B-Day1', base_time + timedelta(minutes=210), 'physical_activity', 'park', 'vigorous')\n",
    "add_event('B-Day1', base_time + timedelta(minutes=240), 'notification', 'park', notification_type='received')\n",
    "add_event('B-Day1', base_time + timedelta(minutes=241), 'self_report', 'park', stress_level=2)\n",
    "add_event('B-Day1', base_time + timedelta(minutes=300), 'exit_location', 'park')\n",
    "add_event('B-Day1', base_time + timedelta(minutes=360), 'enter_location', 'work')\n",
    "add_event('B-Day1', base_time + timedelta(minutes=480), 'notification', 'work', notification_type='received')\n",
    "add_event('B-Day1', base_time + timedelta(minutes=510), 'self_report', 'work', stress_level=5)\n",
    "add_event('B-Day1', base_time + timedelta(minutes=660), 'exit_location', 'work')\n",
    "\n",
    "# User C - Day 1: Non-compliant pattern\n",
    "base_time = datetime(2024, 1, 1, 9, 0)\n",
    "add_event('C-Day1', base_time, 'enter_location', 'work')\n",
    "add_event('C-Day1', base_time + timedelta(minutes=60), 'notification', 'work', notification_type='received')\n",
    "add_event('C-Day1', base_time + timedelta(minutes=120), 'notification', 'work', notification_type='received')\n",
    "add_event('C-Day1', base_time + timedelta(minutes=180), 'notification', 'work', notification_type='received')\n",
    "add_event('C-Day1', base_time + timedelta(minutes=300), 'physical_activity', 'work', 'light')\n",
    "add_event('C-Day1', base_time + timedelta(minutes=480), 'exit_location', 'work')\n",
    "# Note: No self-reports despite multiple notifications\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(event_data)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "print(f\"üìã Event Log Created: {len(df)} events across {df['case_id'].nunique()} cases\")\n",
    "print(f\"üèÉ Event Types: {', '.join(df['event'].unique())}\")\n",
    "print(f\"üìç Locations: {', '.join(df['location'].unique())}\")\n",
    "\n",
    "# Display sample of event log\n",
    "print(\"\\nüìÑ Sample Event Log:\")\n",
    "print(df.head(10).to_string(index=False))\n",
    "\n",
    "# Display the full event log structure\n",
    "print(f\"\\nüìã Complete Event Log Structure:\")\n",
    "print(f\"Total Events: {len(df)}\")\n",
    "print(f\"Unique Cases: {df['case_id'].nunique()}\")\n",
    "print(f\"Event Types: {df['event'].nunique()}\")\n",
    "print(f\"Locations: {df['location'].nunique()}\")\n",
    "print(f\"Time Span: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "\n",
    "# Show event type distribution\n",
    "event_counts = df['event'].value_counts()\n",
    "print(f\"\\nüìä Event Type Distribution:\")\n",
    "for event_type, count in event_counts.items():\n",
    "    print(f\"  {event_type}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# ## 2. Process Mining Analysis\n",
    "\n",
    "if pm4py_available:\n",
    "    # Convert to PM4Py event log format\n",
    "    df_pm4py = df.copy()\n",
    "    df_pm4py = df_pm4py.rename(columns={\n",
    "        'case_id': 'case:concept:name',\n",
    "        'event': 'concept:name',\n",
    "        'timestamp': 'time:timestamp'\n",
    "    })\n",
    "    \n",
    "    # Create event log\n",
    "    event_log = log_converter.apply(df_pm4py)\n",
    "    \n",
    "    print(f\"\\nüîÑ PM4Py Event Log Created: {len(event_log)} traces\")\n",
    "    \n",
    "    # Discover Directly-Follows Graph\n",
    "    dfg = dfg_discovery.apply(event_log)\n",
    "    \n",
    "    # Discover process model using Inductive Miner\n",
    "    net, initial_marking, final_marking = inductive_miner.apply(event_log)\n",
    "    \n",
    "    print(\"\\nüìä Process Discovery Complete\")\n",
    "    print(\"üîç Directly-Follows Graph discovered with transition frequencies\")\n",
    "    print(\"üï∏Ô∏è Petri Net model discovered using Inductive Miner\")\n",
    "    \n",
    "    # Generate Petri Net visualization\n",
    "    try:\n",
    "        gviz = pn_visualizer.apply(net, initial_marking, final_marking)\n",
    "        pn_visualizer.save(gviz, \"petri_net_activity_stress.png\")\n",
    "        print(\"‚úÖ Petri Net saved as 'petri_net_activity_stress.png'\")\n",
    "        \n",
    "        # Also generate DFG visualization\n",
    "        gviz_dfg = dfg_visualizer.apply(dfg, log=event_log, variant=dfg_visualizer.Variants.FREQUENCY)\n",
    "        dfg_visualizer.save(gviz_dfg, \"dfg_activity_stress.png\")\n",
    "        print(\"‚úÖ Directly-Follows Graph saved as 'dfg_activity_stress.png'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Visualization generation failed: {e}\")\n",
    "        print(\"üí° This might be due to missing Graphviz installation\")\n",
    "        \n",
    "    # Display basic statistics about the discovered model\n",
    "    print(f\"\\nüìà Petri Net Statistics:\")\n",
    "    print(f\"   Places: {len(net.places)}\")\n",
    "    print(f\"   Transitions: {len(net.transitions)}\")\n",
    "    print(f\"   Arcs: {len(net.arcs)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Using alternative process analysis without PM4Py\")\n",
    "    \n",
    "    # Create a simple process flow visualization using matplotlib\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    \n",
    "    # Create a simplified process flow diagram\n",
    "    process_steps = ['enter_location', 'physical_activity', 'notification', 'self_report', 'exit_location']\n",
    "    locations = df['location'].unique()\n",
    "    \n",
    "    # Create a flow diagram showing the general process\n",
    "    import matplotlib.patches as patches\n",
    "    \n",
    "    y_positions = {step: i for i, step in enumerate(process_steps)}\n",
    "    x_positions = {loc: i for i, loc in enumerate(locations)}\n",
    "    \n",
    "    # Draw process boxes\n",
    "    for step in process_steps:\n",
    "        rect = patches.Rectangle((0, y_positions[step]-0.3), 3, 0.6, \n",
    "                               linewidth=1, edgecolor='blue', facecolor='lightblue', alpha=0.7)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(1.5, y_positions[step], step.replace('_', ' ').title(), \n",
    "                ha='center', va='center', fontweight='bold')\n",
    "    \n",
    "    # Draw arrows between steps\n",
    "    for i in range(len(process_steps)-1):\n",
    "        ax.annotate('', xy=(1.5, y_positions[process_steps[i+1]]+0.3), \n",
    "                   xytext=(1.5, y_positions[process_steps[i]]-0.3),\n",
    "                   arrowprops=dict(arrowstyle='->', lw=2, color='red'))\n",
    "    \n",
    "    ax.set_xlim(-0.5, 8)\n",
    "    ax.set_ylim(-0.5, len(process_steps)-0.5)\n",
    "    ax.set_title('Simplified Process Flow (Alternative to Petri Net)', fontsize=14, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Add location context\n",
    "    for i, loc in enumerate(locations):\n",
    "        ax.text(5 + i*1.5, 2, loc.title(), ha='center', va='center', \n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='yellow', alpha=0.7),\n",
    "                fontweight='bold')\n",
    "    \n",
    "    ax.text(6, -0.2, 'Context: Different locations affect process execution', \n",
    "            ha='center', va='center', style='italic')\n",
    "    \n",
    "# Add this section after the Petri Net generation to create a custom visualization\n",
    "# ## 2.1 Custom Process Model Visualization\n",
    "\n",
    "def create_custom_petri_net_visualization(df):\n",
    "    \"\"\"Create a custom Petri Net-style visualization of our process\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(14, 10))\n",
    "    \n",
    "    # Define the process structure based on our event log\n",
    "    places = ['Start', 'At_Location', 'Activity_Done', 'Notified', 'Reported', 'End']\n",
    "    transitions = ['enter_location', 'physical_activity', 'notification', 'self_report', 'exit_location']\n",
    "    \n",
    "    # Position places (circles) and transitions (rectangles)\n",
    "    place_positions = {\n",
    "        'Start': (1, 5),\n",
    "        'At_Location': (3, 5),\n",
    "        'Activity_Done': (5, 6),\n",
    "        'Notified': (5, 4),\n",
    "        'Reported': (7, 5),\n",
    "        'End': (9, 5)\n",
    "    }\n",
    "    \n",
    "    transition_positions = {\n",
    "        'enter_location': (2, 5),\n",
    "        'physical_activity': (4, 6),\n",
    "        'notification': (4, 4),\n",
    "        'self_report': (6, 5),\n",
    "        'exit_location': (8, 5)\n",
    "    }\n",
    "    \n",
    "    # Draw places as circles\n",
    "    for place, (x, y) in place_positions.items():\n",
    "        circle = plt.Circle((x, y), 0.3, color='lightblue', ec='blue', linewidth=2)\n",
    "        ax.add_patch(circle)\n",
    "        ax.text(x, y, place.replace('_', '\\n'), ha='center', va='center', \n",
    "                fontsize=8, fontweight='bold')\n",
    "    \n",
    "    # Draw transitions as rectangles\n",
    "    for transition, (x, y) in transition_positions.items():\n",
    "        rect = patches.Rectangle((x-0.4, y-0.2), 0.8, 0.4, \n",
    "                               linewidth=2, edgecolor='red', facecolor='lightcoral')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x, y, transition.replace('_', '\\n'), ha='center', va='center', \n",
    "                fontsize=7, fontweight='bold')\n",
    "    \n",
    "    # Draw arcs (arrows)\n",
    "    arcs = [\n",
    "        ('Start', 'enter_location'),\n",
    "        ('enter_location', 'At_Location'),\n",
    "        ('At_Location', 'physical_activity'),\n",
    "        ('At_Location', 'notification'),\n",
    "        ('physical_activity', 'Activity_Done'),\n",
    "        ('notification', 'Notified'),\n",
    "        ('Activity_Done', 'self_report'),\n",
    "        ('Notified', 'self_report'),\n",
    "        ('self_report', 'Reported'),\n",
    "        ('Reported', 'exit_location'),\n",
    "        ('exit_location', 'End')\n",
    "    ]\n",
    "    \n",
    "    for source, target in arcs:\n",
    "        if source in place_positions:\n",
    "            x1, y1 = place_positions[source]\n",
    "        else:\n",
    "            x1, y1 = transition_positions[source]\n",
    "            \n",
    "        if target in place_positions:\n",
    "            x2, y2 = place_positions[target]\n",
    "        else:\n",
    "            x2, y2 = transition_positions[target]\n",
    "        \n",
    "        # Calculate arrow positions to avoid overlap with shapes\n",
    "        dx, dy = x2 - x1, y2 - y1\n",
    "        length = np.sqrt(dx**2 + dy**2)\n",
    "        if length > 0:\n",
    "            dx_norm, dy_norm = dx/length, dy/length\n",
    "            start_x, start_y = x1 + 0.3*dx_norm, y1 + 0.3*dy_norm\n",
    "            end_x, end_y = x2 - 0.3*dx_norm, y2 - 0.3*dy_norm\n",
    "            \n",
    "            ax.annotate('', xy=(end_x, end_y), xytext=(start_x, start_y),\n",
    "                       arrowprops=dict(arrowstyle='->', lw=1.5, color='black'))\n",
    "    \n",
    "    # Add parallel path indication\n",
    "    ax.annotate('', xy=(4.5, 5.5), xytext=(4.5, 4.5),\n",
    "               arrowprops=dict(arrowstyle='<->', lw=2, color='green'))\n",
    "    ax.text(4.8, 5, 'Parallel\\nPaths', ha='left', va='center', \n",
    "            fontsize=8, color='green', fontweight='bold')\n",
    "    \n",
    "    # Add location context boxes\n",
    "    locations = ['Home', 'Gym', 'Work', 'Park']\n",
    "    colors = ['lightgreen', 'orange', 'lightcoral', 'lightblue']\n",
    "    \n",
    "    for i, (loc, color) in enumerate(zip(locations, colors)):\n",
    "        rect = patches.Rectangle((0.2, 7-i*0.6), 1.5, 0.4, \n",
    "                               linewidth=1, edgecolor='gray', facecolor=color, alpha=0.7)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(0.95, 7.2-i*0.6, f'{loc} Context', ha='center', va='center', \n",
    "                fontsize=8, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlim(0, 10)\n",
    "    ax.set_ylim(3, 8)\n",
    "    ax.set_title('Custom Petri Net: Activity & Stress Monitoring Process\\n(Shows Parallel Paths and Location Context)', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Add legend\n",
    "    legend_elements = [\n",
    "        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='lightblue', \n",
    "                  markersize=10, markeredgecolor='blue', label='Places (Process States)'),\n",
    "        plt.Line2D([0], [0], marker='s', color='w', markerfacecolor='lightcoral', \n",
    "                  markersize=8, markeredgecolor='red', label='Transitions (Activities)'),\n",
    "        plt.Line2D([0], [0], color='black', linewidth=2, label='Process Flow'),\n",
    "        plt.Line2D([0], [0], color='green', linewidth=2, label='Parallel Execution')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(0.98, 0.98))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('custom_petri_net_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate the custom Petri Net visualization\n",
    "custom_petri_fig = create_custom_petri_net_visualization(df)\n",
    "print(\"‚úÖ Custom Petri Net visualization saved as 'custom_petri_net_visualization.png'\")\n",
    "\n",
    "# ## 3. Process Mining Insights\n",
    "\n",
    "def analyze_process_patterns(df):\n",
    "    \"\"\"Extract process-specific insights that other techniques would miss\"\"\"\n",
    "    \n",
    "    patterns = []\n",
    "    \n",
    "    # Group by case to analyze individual process instances\n",
    "    for case_id in df['case_id'].unique():\n",
    "        case_events = df[df['case_id'] == case_id].sort_values('timestamp')\n",
    "        \n",
    "        # Extract process pattern\n",
    "        event_sequence = ' ‚Üí '.join(case_events['event'].tolist())\n",
    "        locations = case_events['location'].unique()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        notifications = len(case_events[case_events['event'] == 'notification'])\n",
    "        self_reports = len(case_events[case_events['event'] == 'self_report'])\n",
    "        activities = len(case_events[case_events['event'] == 'physical_activity'])\n",
    "        \n",
    "        compliance_rate = self_reports / notifications if notifications > 0 else 0\n",
    "        avg_stress = case_events['stress_level'].mean()\n",
    "        \n",
    "        # Detect parallel activities (same timestamp)\n",
    "        parallel_activities = case_events.groupby('timestamp').size().max() > 1\n",
    "        \n",
    "        patterns.append({\n",
    "            'case_id': case_id,\n",
    "            'process_pattern': event_sequence,\n",
    "            'locations': list(locations),\n",
    "            'compliance_rate': compliance_rate,\n",
    "            'avg_stress': avg_stress,\n",
    "            'notifications': notifications,\n",
    "            'self_reports': self_reports,\n",
    "            'activities': activities,\n",
    "            'has_parallel_activities': parallel_activities,\n",
    "            'process_duration': (case_events['timestamp'].max() - case_events['timestamp'].min()).total_seconds() / 3600\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(patterns)\n",
    "\n",
    "process_patterns = analyze_process_patterns(df)\n",
    "\n",
    "print(\"\\nüéØ Process Mining Patterns Discovered:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for _, pattern in process_patterns.iterrows():\n",
    "    print(f\"\\nüìã Case: {pattern['case_id']}\")\n",
    "    print(f\"üîÑ Process Flow: {pattern['process_pattern'][:100]}...\")\n",
    "    print(f\"üìç Locations: {', '.join(pattern['locations'])}\")\n",
    "    print(f\"‚úÖ Compliance Rate: {pattern['compliance_rate']:.1%}\")\n",
    "    print(f\"üò∞ Avg Stress: {pattern['avg_stress']:.1f}\")\n",
    "    print(f\"‚ö° Parallel Activities: {'Yes' if pattern['has_parallel_activities'] else 'No'}\")\n",
    "    print(f\"‚è±Ô∏è Duration: {pattern['process_duration']:.1f} hours\")\n",
    "\n",
    "# ## 4. Traditional Time Series Analysis\n",
    "\n",
    "def create_time_series_view(df):\n",
    "    \"\"\"Show what traditional time series analysis would reveal\"\"\"\n",
    "    \n",
    "    # Aggregate by hour\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    \n",
    "    time_series = df.groupby('hour').agg({\n",
    "        'stress_level': 'mean',\n",
    "        'event': 'count'\n",
    "    }).reset_index()\n",
    "    \n",
    "    time_series.columns = ['hour', 'avg_stress', 'event_count']\n",
    "    \n",
    "    # Add activity counts\n",
    "    activity_counts = df[df['event'] == 'physical_activity'].groupby(\n",
    "        df[df['event'] == 'physical_activity']['timestamp'].dt.hour\n",
    "    ).size().reindex(range(24), fill_value=0)\n",
    "    \n",
    "    time_series = time_series.merge(\n",
    "        activity_counts.reset_index().rename(columns={'timestamp': 'hour', 0: 'activity_count'}),\n",
    "        on='hour', how='left'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    return time_series\n",
    "\n",
    "time_series_data = create_time_series_view(df)\n",
    "\n",
    "# Visualize time series\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Analytical Technique Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Time Series View\n",
    "axes[0, 0].plot(time_series_data['hour'], time_series_data['avg_stress'], 'r-o', label='Avg Stress')\n",
    "axes[0, 0].set_title('Time Series Analysis')\n",
    "axes[0, 0].set_xlabel('Hour of Day')\n",
    "axes[0, 0].set_ylabel('Average Stress Level')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Activity Distribution\n",
    "location_activity = df[df['event'] == 'physical_activity']['location'].value_counts()\n",
    "axes[0, 1].bar(location_activity.index, location_activity.values, color='green', alpha=0.7)\n",
    "axes[0, 1].set_title('Activity Distribution by Location')\n",
    "axes[0, 1].set_xlabel('Location')\n",
    "axes[0, 1].set_ylabel('Activity Count')\n",
    "\n",
    "# Process Compliance by Location\n",
    "compliance_by_location = df.groupby('location').apply(\n",
    "    lambda x: len(x[x['event'] == 'self_report']) / max(len(x[x['event'] == 'notification']), 1)\n",
    ").reset_index()\n",
    "compliance_by_location.columns = ['location', 'compliance_rate']\n",
    "\n",
    "axes[1, 0].bar(compliance_by_location['location'], compliance_by_location['compliance_rate'], \n",
    "               color='blue', alpha=0.7)\n",
    "axes[1, 0].set_title('Process Mining: Compliance by Location')\n",
    "axes[1, 0].set_xlabel('Location')\n",
    "axes[1, 0].set_ylabel('Compliance Rate')\n",
    "axes[1, 0].set_ylim(0, 1)\n",
    "\n",
    "# Stress by Process Pattern\n",
    "stress_by_case = process_patterns[['case_id', 'avg_stress', 'locations']].dropna()\n",
    "stress_by_case['location_type'] = stress_by_case['locations'].apply(\n",
    "    lambda x: 'work' if 'work' in x else ('gym' if 'gym' in x else 'home/park')\n",
    ")\n",
    "\n",
    "sns.boxplot(data=stress_by_case, x='location_type', y='avg_stress', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Stress Levels by Process Context')\n",
    "axes[1, 1].set_xlabel('Primary Location Context')\n",
    "axes[1, 1].set_ylabel('Average Stress Level')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ## 5. Sequential Pattern Mining Simulation\n",
    "\n",
    "def find_sequential_patterns(df, min_support=0.3):\n",
    "    \"\"\"Simulate sequential pattern mining results\"\"\"\n",
    "    \n",
    "    patterns = {}\n",
    "    \n",
    "    # Extract sequences for each case\n",
    "    for case_id in df['case_id'].unique():\n",
    "        case_events = df[df['case_id'] == case_id].sort_values('timestamp')\n",
    "        events = case_events['event'].tolist()\n",
    "        \n",
    "        # Generate 2-grams and 3-grams\n",
    "        for i in range(len(events)-1):\n",
    "            pattern = f\"{events[i]} ‚Üí {events[i+1]}\"\n",
    "            patterns[pattern] = patterns.get(pattern, 0) + 1\n",
    "            \n",
    "            if i < len(events)-2:\n",
    "                pattern_3 = f\"{events[i]} ‚Üí {events[i+1]} ‚Üí {events[i+2]}\"\n",
    "                patterns[pattern_3] = patterns.get(pattern_3, 0) + 1\n",
    "    \n",
    "    # Calculate support\n",
    "    total_cases = df['case_id'].nunique()\n",
    "    frequent_patterns = {\n",
    "        pattern: count/total_cases \n",
    "        for pattern, count in patterns.items() \n",
    "        if count/total_cases >= min_support\n",
    "    }\n",
    "    \n",
    "    return frequent_patterns\n",
    "\n",
    "sequential_patterns = find_sequential_patterns(df)\n",
    "\n",
    "print(\"\\nüîó Sequential Pattern Mining Results:\")\n",
    "print(\"=\"*50)\n",
    "for pattern, support in sorted(sequential_patterns.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"Pattern: {pattern}\")\n",
    "    print(f\"Support: {support:.1%}\\n\")\n",
    "\n",
    "# ## 6. Comparative Analysis Summary\n",
    "\n",
    "print(\"\\nüìä COMPARATIVE ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüéØ PROCESS MINING UNIQUE INSIGHTS:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"‚úÖ Complete process flows with branching logic\")\n",
    "print(\"‚úÖ Contextual behavioral variants by location\")\n",
    "print(\"‚úÖ Individual compliance patterns and deviations\")\n",
    "print(\"‚úÖ Parallel activity detection and analysis\")\n",
    "print(\"‚úÖ End-to-end process performance metrics\")\n",
    "print(\"‚úÖ Resource-specific behavioral patterns\")\n",
    "\n",
    "print(\"\\nüìà TIME SERIES ANALYSIS LIMITATIONS:\")\n",
    "print(\"-\" * 45)\n",
    "print(\"‚ùå No process flow or sequence information\")\n",
    "print(\"‚ùå Cannot identify behavioral variants\")\n",
    "print(\"‚ùå Missing causal relationships\")\n",
    "print(\"‚ùå Aggregate view obscures individual patterns\")\n",
    "print(\"‚ùå No compliance or conformance analysis\")\n",
    "\n",
    "print(\"\\nüîó SEQUENTIAL MINING LIMITATIONS:\")\n",
    "print(\"-\" * 42)\n",
    "print(\"‚ùå No branching logic or conditional paths\")\n",
    "print(\"‚ùå Limited contextual integration\")\n",
    "print(\"‚ùå Cannot handle parallel activities\")\n",
    "print(\"‚ùå No resource or case-level analysis\")\n",
    "print(\"‚ùå Missing process variants identification\")\n",
    "\n",
    "print(\"\\nüèÜ KEY PROCESS MINING ADVANTAGES FOR THIS CASE:\")\n",
    "print(\"-\" * 55)\n",
    "print(\"1. üè† Location Context Integration: Shows how physical environment\")\n",
    "print(\"   affects entire behavioral process, not just individual activities\")\n",
    "print(\"\\n2. üîÑ Behavioral Variant Discovery: Identifies that same user follows\")\n",
    "print(\"   completely different patterns based on location context\")\n",
    "print(\"\\n3. ‚úÖ Compliance Analysis: Reveals WHERE and WHY users deviate\")\n",
    "print(\"   from intended self-monitoring behaviors\")\n",
    "print(\"\\n4. ‚ö° Parallel Execution Detection: Identifies users who can handle\")\n",
    "print(\"   simultaneous activities vs. those requiring sequential approach\")\n",
    "print(\"\\n5. üéØ Holistic Process Intelligence: Links environmental factors\")\n",
    "print(\"   to complete process execution patterns, enabling targeted interventions\")\n",
    "\n",
    "# ## 7. Actionable Insights from Process Mining\n",
    "\n",
    "print(\"\\nüí° ACTIONABLE INSIGHTS FROM PROCESS MINING:\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "print(\"\\nüè¢ Work Environment Intervention Needed:\")\n",
    "print(\"   - Work location disrupts self-monitoring compliance\")\n",
    "print(\"   - Consider workplace-specific notification strategies\")\n",
    "print(\"   - Higher stress levels correlate with poor process adherence\")\n",
    "\n",
    "print(\"\\nüèÉ‚Äç‚ôÇÔ∏è Exercise Locations Optimize Behavior:\")\n",
    "print(\"   - Gym and park locations show highest compliance rates\")\n",
    "print(\"   - Exercise activities correlate with lower stress AND better reporting\")\n",
    "print(\"   - Consider promoting outdoor/gym activities for dual benefits\")\n",
    "\n",
    "print(\"\\nüë§ Individual Process Patterns:\")\n",
    "print(\"   - User A: Location-dependent compliance (good at home/gym, poor at work)\")\n",
    "print(\"   - User B: Capable of parallel activities, highly adaptable\")\n",
    "print(\"   - User C: Generally non-compliant, needs different intervention approach\")\n",
    "\n",
    "print(\"\\nüéØ Process Optimization Recommendations:\")\n",
    "print(\"   - Implement location-aware notification timing\")\n",
    "print(\"   - Design parallel activity support for capable users\")\n",
    "print(\"   - Create work-specific stress management protocols\")\n",
    "print(\"   - Use exercise promotion as dual intervention strategy\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìã Analysis Complete - Process Mining provides comprehensive\")\n",
    "print(\"   behavioral insights impossible with traditional techniques!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
